\relax 
\citation{shannon,turing}
\citation{deepblue}
\citation{sota}
\citation{samuel}
\citation{tesauro}
\citation{giraffe}
\citation{meep}
\citation{deepchess}
\citation{atari}
\citation{dddqn}
\citation{alphago}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{abstract.xdy}
\@glsorder{word}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}}
\newlabel{sec:relwork}{{II}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Deep Reinforcement Learning Framework for Chess}{1}}
\newlabel{sec:drl}{{III}{1}}
\citation{rl}
\citation{rl}
\citation{rlalg}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Reinforcement Learning}{2}}
\newlabel{sec:rl}{{III-A}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Supervised Learning}{2}}
\newlabel{sec:sl}{{III-B}{2}}
\newlabel{eq:blackbox}{{7}{2}}
\newlabel{eq:insight}{{8}{2}}
\citation{knightcap,meep}
\citation{convergence}
\citation{init}
\@writefile{toc}{\contentsline {section}{\numberline {IV}TD-Learning}{3}}
\newlabel{sec:td}{{IV}{3}}
\newlabel{eq:td0}{{10}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}TD-($\lambda $)}{3}}
\newlabel{eq:tdlambda}{{11}{3}}
\newlabel{eq:target}{{12}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}TD-Leaf($\lambda $)}{3}}
\newlabel{tdl}{{13}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison between the 3 discussed TD-learning algorithms, the \Gls {pv} are indicated with solid edges. In classical TD-learning the updates are between successive states. TD-leaf updates are between successive leaf nodes and in TD-stem both ideas are combined. \relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:algs}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}TD-Stem($\lambda $)}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Network Architecture}{3}}
\newlabel{sec:nn}{{V}{3}}
\citation{tb}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax }}{4}}
\newlabel{fig:diagram}{{2}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces 8 Bitboards corresponding to the chess position in figure \ref  {fig:diagram}. Piece maps indicate the cells where pieces reside. Mobility maps show where pieces can go to.\relax }}{4}}
\newlabel{tab:feat}{{I}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Experiments}{4}}
\newlabel{sec:res}{{VI}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Hyper-parameters modifiable in between stages.\relax }}{4}}
\newlabel{tab:params_exp}{{II}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Hyper-parameters of the stages in the experiments\relax }}{4}}
\newlabel{tab:stages}{{III}{4}}
\newlabel{fig:fnn}{{3a}{5}}
\newlabel{sub@fig:fnn}{{a}{5}}
\newlabel{fig:cnn1}{{3b}{5}}
\newlabel{sub@fig:cnn1}{{b}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Network architectures used for the value function during the experiments.\relax }}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Performance comparison TD-Leaf($\lambda $) and TD-Stem($\lambda $),$N$ is the total number of episodes played in the simulation.\relax }}{5}}
\newlabel{tab:perf_krk}{{IV}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-A}Experiment 1: king rook king endgame}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-B}Experiment 2: king queen king endgame}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Performance comparison TD-Leaf($\lambda $) and TD-Stem($\lambda $)\relax }}{5}}
\newlabel{tab:perf_kqk}{{V}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The learning curve of the second experiment, divided in 5 stages.\relax }}{5}}
\newlabel{fig:lc_kqk}{{4}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{5}}
\newlabel{sec:con}{{VII}{5}}
\citation{*}
\bibstyle{phdsymp}
\bibcite{shannon}{1}
\bibcite{turing}{2}
\bibcite{deepblue}{3}
\bibcite{sota}{4}
\bibcite{samuel}{5}
\bibcite{tesauro}{6}
\bibcite{knightcap}{7}
\bibcite{giraffe}{8}
\bibcite{meep}{9}
\bibcite{deepchess}{10}
\bibcite{atari}{11}
\bibcite{dddqn}{12}
\bibcite{alphago}{13}
\bibcite{rl}{14}
\bibcite{alphabeta}{15}
\bibcite{rlalg}{16}
\bibcite{convergence}{17}
\bibcite{tb}{18}
\bibcite{init}{19}
